{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sutton book_ chapter 2_ Bandit problem\n",
    "\n",
    "\n",
    "### Explanation by Wonseok Jung\n",
    "forked from ShangtongZhang/reinforcement-learning-an-introduction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arms=10\n",
    "epsilon=0.\n",
    "initial=0.\n",
    "stepsize=0.1\n",
    "sampleAverages=False\n",
    "indices=np.arange(Arms)\n",
    "\n",
    "trueReward=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976, 0.3637971737362486]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0, 0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976, 0.3637971737362486, -0.8922416354424973]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0, 0, 0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976, 0.3637971737362486, -0.8922416354424973, -0.5392348526880139]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0, 0, 0, 0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976, 0.3637971737362486, -0.8922416354424973, -0.5392348526880139, -0.5944456321565794]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0, 0, 0, 0, 0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976, 0.3637971737362486, -0.8922416354424973, -0.5392348526880139, -0.5944456321565794, -1.5098433548799228]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0, 0, 0, 0, 0, 0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976, 0.3637971737362486, -0.8922416354424973, -0.5392348526880139, -0.5944456321565794, -1.5098433548799228, -0.6149914826068681]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976, 0.3637971737362486, -0.8922416354424973, -0.5392348526880139, -0.5944456321565794, -1.5098433548799228, -0.6149914826068681, 1.0894590560106605]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "각 행동에 대한 진짜 리워드 is [-0.5344554566709963, 1.2573005820613976, 0.3637971737362486, -0.8922416354424973, -0.5392348526880139, -0.5944456321565794, -1.5098433548799228, -0.6149914826068681, 1.0894590560106605, 0.9519024698792299]\n",
      "각 행동 estimation [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "각 행동 numuer of chosen [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#각 행동에 대한 진짜 리워드\n",
    "\n",
    "qTrue=[]\n",
    "\n",
    "#각 행동 estimation\n",
    "qEst=np.zeros(Arms)\n",
    "\n",
    "#각 행동 numuer of chosen \n",
    "actionCount=[]\n",
    "\n",
    "for i in range(0,Arms):\n",
    "   \n",
    "    qTrue.append(np.random.randn() + trueReward)\n",
    "    print(\"각 행동에 대한 진짜 리워드 is\",qTrue)\n",
    "    qEst[i]= initial\n",
    "    print(\"각 행동 estimation\",qEst)\n",
    "    actionCount.append(0)\n",
    "    print(\"각 행동 numuer of chosen\", actionCount)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAction=np.argmax(qTrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.5344554566709963,\n",
       " 1.2573005820613976,\n",
       " 0.3637971737362486,\n",
       " -0.8922416354424973,\n",
       " -0.5392348526880139,\n",
       " -0.5944456321565794,\n",
       " -1.5098433548799228,\n",
       " -0.6149914826068681,\n",
       " 1.0894590560106605,\n",
       " 0.9519024698792299]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qTrue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bestAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAction():\n",
    "    #explore1\n",
    "    if epsilon>0:\n",
    "        if np.random.binomial(1,epsilon)==1:\n",
    "           \n",
    "            np.random.shuffle(indices)\n",
    "            return indices[0]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.random.binomial function\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.binomial.html\n",
    "\n",
    "n, p = 10, .5  # number of trials, probability of each trial\n",
    "s = np.random.binomial(n, p, 1000)\n",
    "-> result of flipping a coin 10 times, tested 1000 times.\n",
    "\n",
    "Question? \n",
    "A real world example. A company drills 9 wild-cat oil exploration wells, each with an estimated probability of success of 0.1. All nine wells fail. What is the probability of that happening?\n",
    "\n",
    "Let’s do 20,000 trials of the model, and count the number that generate zero positive results.\n",
    "\n",
    "sum(np.random.binomial(9, 0.1, 20000) == 0)/20000.\n",
    "answer = 0.38885, or 38%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0부터 9까지의 배열을 랜덤하게 뽑게 해주는 함수\n",
    "조금 복잡해서 나라면 이렇게 다르게 만들었을것 같다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epsilon=0.5\n",
    "def get_action_ws():\n",
    "    #explore part\n",
    "    if np.random.rand() <= epsilon:\n",
    "        print(\"random action\")\n",
    "        return random.randrange(Arms)\n",
    "    #exploit part\n",
    "    ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_action_ws()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
